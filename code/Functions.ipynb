{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7994cbdd-10b2-4d7a-80d8-b432633bf6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from load_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80839df2-7419-4768-9d00-b0c42cbd92db",
   "metadata": {},
   "source": [
    "## Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62e0afa-2636-4035-a573-1f1c9736e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    mean_x = np.mean(x, axis = 0)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x, axis = 0)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x\n",
    "\n",
    "\n",
    "def build_model_data(x_std, y_data):\n",
    "    y = y_data\n",
    "    x = x_std\n",
    "    num_samples = len(y)\n",
    "    tx = np.c_[np.ones(num_samples), x]\n",
    "    return y, tx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2be9d73-72b1-4a5d-a841-7703cca02c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # generate random indices\n",
    "    data = np.vstack([y,x.T]).T\n",
    "    per_data = np.random.permutation(data) \n",
    "    idx = int(np.floor(x.shape[0]*ratio))\n",
    "    train_data = per_data[:idx]\n",
    "    test_data = per_data[idx:]\n",
    "    train_x, train_y = train_data[:, 1:], train_data[:, 0]\n",
    "    test_x, test_y = test_data[:, 1:], test_data[:, 0]\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b09e77-2274-4015-9238-e2a36e9de4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(features, labels, col = True, row = False, mean = False, ratio = 0.7):\n",
    "    \n",
    "    #deleting all features (=coloums) with missing values\n",
    "    if col:\n",
    "        idx = np.where(features == -999)[1]\n",
    "        processed_f = np.delete(features, idx, 1)\n",
    "        processed_l = labels\n",
    "    \n",
    "    #deleting all rows with missing values\n",
    "    if row:\n",
    "        idx = np.where(features == -999)[0]\n",
    "        processed_f = np.delete(features, idx, 0)\n",
    "        processed_l = np.delete(labels, idx, 0)   \n",
    "    \n",
    "    #replace all missing values by the coloum-mean of the remaining values\n",
    "    if mean:\n",
    "        processed_f = features.copy()\n",
    "        processed_f[processed_f == -999] = np.nan\n",
    "        means = np.nanmean(processed_f, axis = 0)\n",
    "        idx = np.where(np.isnan(processed_f))\n",
    "        processed_f[idx] = np.take(means, idx[1]) \n",
    "        processed_l = labels\n",
    "        \n",
    "    \n",
    "    \n",
    "    #standardize each feature \n",
    "    processed_f, mean_f, std_f = standardize(processed_f)\n",
    "    \n",
    "    #split the data into a training and test set\n",
    "    train_x, train_y, test_x, test_y = split_data(processed_f, processed_l, ratio, seed=1)\n",
    "    \n",
    "    #build train- and testmodel (feature matrix tx, label vector y)\n",
    "    train_y, train_tx = build_model_data(train_x, train_y)\n",
    "    test_y, test_tx = build_model_data(test_x, test_y) \n",
    "           \n",
    "    return train_tx, train_y, test_tx, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cda94d2-1a98-449e-845f-762b36f82833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(train_tx, train_y, test_tx, test_y, weights):\n",
    "    \n",
    "    #Make predictions\n",
    "    train_pred = train_tx.dot(weights)\n",
    "    test_pred = test_tx.dot(weights)\n",
    "    \n",
    "    #Transform the prediction into 0 ( = 's') and 1 (= 'b')\n",
    "    train_pred = np.where(train_pred > 0.5, 1, 0)\n",
    "    test_pred = np.where(test_pred > 0.5, 1, 0)\n",
    "    \n",
    "    #Compute the ratio of correct labled predictions\n",
    "    train_score = np.sum(np.where(train_pred == train_y, 1 , 0)) / len(train_pred)\n",
    "    test_score = np.sum(np.where(test_pred == test_y, 1 , 0)) / len(test_pred)\n",
    "    \n",
    "    print(\"There are {train_s}% correct prediction in the training set\".format(train_s = train_score*100))\n",
    "    print(\"There are {test_s}% correct prediction in the test set\".format(test_s = test_score*100))\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd61b1-6f87-4950-b455-1d3a696c3e73",
   "metadata": {},
   "source": [
    "## How to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6035b88-d6ea-493f-adf1-42ab09bb5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694e233b-a534-4c2c-9a59-f8d3730ba9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73.36399999999999% correct prediction in the training set\n",
      "There are 73.30266666666667% correct prediction in the test set\n"
     ]
    }
   ],
   "source": [
    "train_tx, train_y, test_tx, test_y = preprocessing(features, labels)\n",
    "weights, loss = least_squares(train_y, train_tx)\n",
    "train_score, test_score = correctness(train_tx, train_y, test_tx, test_y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb05f8b-9376-48da-afd4-dca60e9a205a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72.69238029321085% correct prediction in the training set\n",
      "There are 72.40029361389773% correct prediction in the test set\n"
     ]
    }
   ],
   "source": [
    "train_tx, train_y, test_tx, test_y = preprocessing(features, labels, col = False, row = True)\n",
    "weights, loss = least_squares(train_y, train_tx)\n",
    "train_score, test_score = correctness(train_tx, train_y, test_tx, test_y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbcf56-fb21-4665-9557-e6067318486a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63800d69-65fc-46fd-8ba2-89f8f488a351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
